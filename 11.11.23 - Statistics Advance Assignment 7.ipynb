{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7239bdd9-9d8e-4a9c-a721-876d918c9fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Ans 01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8764ed9-3603-44ce-bd3f-53910eba2317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-value: 1.1212392144314698\n",
      "P-value: 0.7600634212344075\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def variance_ratio_test(data1, data2):\n",
    "    \"\"\"\n",
    "    Perform a variance ratio test (F-test) on two arrays of data.\n",
    "\n",
    "    Parameters:\n",
    "    - data1: Array of data for the first group.\n",
    "    - data2: Array of data for the second group.\n",
    "\n",
    "    Returns:\n",
    "    - f_value: The calculated F-value.\n",
    "    - p_value: The corresponding p-value for the F-test.\n",
    "    \"\"\"\n",
    "    # Calculate variances\n",
    "    var1 = np.var(data1, ddof=1)\n",
    "    var2 = np.var(data2, ddof=1)\n",
    "\n",
    "    # Calculate F-value\n",
    "    f_value = var1 / var2 if var1 >= var2 else var2 / var1\n",
    "\n",
    "    # Degrees of freedom\n",
    "    df1 = len(data1) - 1\n",
    "    df2 = len(data2) - 1\n",
    "\n",
    "    # Calculate p-value\n",
    "    p_value = 2 * min(f.cdf(f_value, df1, df2), 1 - f.cdf(f_value, df1, df2))\n",
    "\n",
    "    return f_value, p_value\n",
    "\n",
    "# Example usage:\n",
    "data_group1 = np.random.normal(loc=10, scale=2, size=30)\n",
    "data_group2 = np.random.normal(loc=12, scale=2, size=30)\n",
    "\n",
    "f_value, p_value = variance_ratio_test(data_group1, data_group2)\n",
    "\n",
    "print(f\"F-value: {f_value}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0a45ac7-af37-443f-8785-4a58175b76e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#Ans 02:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b9ef44-64e4-4448-bab3-0d62aecac994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical F-value: 3.8586986662732143\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "def critical_f_value(alpha, df_num, df_den):\n",
    "    \"\"\"\n",
    "    Calculate the critical F-value for a given significance level and degrees of freedom.\n",
    "\n",
    "    Parameters:\n",
    "    - alpha: Significance level (e.g., 0.05 for a 5% significance level).\n",
    "    - df_num: Degrees of freedom for the numerator.\n",
    "    - df_den: Degrees of freedom for the denominator.\n",
    "\n",
    "    Returns:\n",
    "    - critical_f: The critical F-value.\n",
    "    \"\"\"\n",
    "    # Calculate critical F-value\n",
    "    critical_f = f.ppf(1 - alpha / 2, df_num, df_den)\n",
    "\n",
    "    return critical_f\n",
    "\n",
    "# Example usage:\n",
    "alpha = 0.05\n",
    "df_num = 3  # Replace with the actual degrees of freedom for the numerator\n",
    "df_den = 20  # Replace with the actual degrees of freedom for the denominator\n",
    "\n",
    "critical_f = critical_f_value(alpha, df_num, df_den)\n",
    "print(f\"Critical F-value: {critical_f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02719401-916d-4e8a-bd76-98ac46943aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#Ans 03:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b373ec-4b0a-449f-8159-e85b70d2bdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-value: 1.0702949631678573\n",
      "Degrees of Freedom (numerator): 29\n",
      "Degrees of Freedom (denominator): 29\n",
      "P-value: 0.8561073337841736\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def f_test_for_equal_variances(sample1, sample2):\n",
    "    \"\"\"\n",
    "    Perform an F-test for equality of variances on two samples.\n",
    "\n",
    "    Parameters:\n",
    "    - sample1: First sample (numpy array).\n",
    "    - sample2: Second sample (numpy array).\n",
    "\n",
    "    Returns:\n",
    "    - f_value: The calculated F-value.\n",
    "    - df1: Degrees of freedom for the numerator.\n",
    "    - df2: Degrees of freedom for the denominator.\n",
    "    - p_value: The corresponding p-value for the F-test.\n",
    "    \"\"\"\n",
    "    # Calculate variances\n",
    "    var1 = np.var(sample1, ddof=1)\n",
    "    var2 = np.var(sample2, ddof=1)\n",
    "\n",
    "    # Degrees of freedom\n",
    "    df1 = len(sample1) - 1\n",
    "    df2 = len(sample2) - 1\n",
    "\n",
    "    # Calculate F-value\n",
    "    f_value = var1 / var2 if var1 >= var2 else var2 / var1\n",
    "\n",
    "    # Calculate p-value\n",
    "    p_value = 2 * min(f.cdf(f_value, df1, df2), 1 - f.cdf(f_value, df1, df2))\n",
    "\n",
    "    return f_value, df1, df2, p_value\n",
    "\n",
    "# Example usage:\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "# Generate random samples with known variances\n",
    "sample1 = np.random.normal(loc=10, scale=2, size=30)\n",
    "sample2 = np.random.normal(loc=10, scale=2, size=30)\n",
    "\n",
    "# Perform F-test\n",
    "f_value, df1, df2, p_value = f_test_for_equal_variances(sample1, sample2)\n",
    "\n",
    "# Print results\n",
    "print(f\"F-value: {f_value}\")\n",
    "print(f\"Degrees of Freedom (numerator): {df1}\")\n",
    "print(f\"Degrees of Freedom (denominator): {df2}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1af1b9c8-051b-49d3-bc5f-6b02bc0c923a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#Ans 04:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99a97c61-4396-4f08-b599-3213f17410c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical F-value: 3.473699051085809\n",
      "F-statistic: 0.6666666666666666\n",
      "P-value: 0.5123897987357996\n",
      "Fail to reject the null hypothesis. No significant difference in variances.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "# Given data\n",
    "variance1 = 10\n",
    "variance2 = 15\n",
    "sample_size = 12\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "# Degrees of freedom\n",
    "df1 = sample_size - 1\n",
    "df2 = sample_size - 1\n",
    "\n",
    "# Critical F-value for a two-tailed test\n",
    "critical_f = f.ppf(1 - alpha / 2, df1, df2)\n",
    "\n",
    "# F-test statistic\n",
    "f_statistic = variance1 / variance2\n",
    "\n",
    "# P-value for the F-test\n",
    "p_value = 2 * min(f.cdf(f_statistic, df1, df2), 1 - f.cdf(f_statistic, df1, df2))\n",
    "\n",
    "# Print results\n",
    "print(f\"Critical F-value: {critical_f}\")\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Compare with critical value\n",
    "if abs(f_statistic) > critical_f:\n",
    "    print(\"Reject the null hypothesis. Variances are significantly different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. No significant difference in variances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34628248-ff32-497f-a8eb-3142c0d71a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#Ans 05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5928cfb7-0cff-4899-926e-ae34858b2dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In this case, you want to test whether the sample variance is significantly different from the claimed\n",
    "# population variance. The hypotheses are:\n",
    "\n",
    "# Null Hypothesis (H0): The population variance is equal to the claimed variance (σ**2 = 0.005 ).\n",
    "# Alternative Hypothesis (H1): The population variance is not equal to the claimed variance (σ**2 != 0.005 ).\n",
    "# The test statistic (F-statistic) is calculated as:\n",
    "#     F=  s**2/σ**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d52015ef-3159-4457-b7f8-7c8600f7e7fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical F-value: 24939.565259943236\n",
      "F-statistic: 1.2\n",
      "P-value: 0.7407800760081285\n",
      "Fail to reject the null hypothesis. The claim is justified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "# Given data\n",
    "claimed_variance = 0.005\n",
    "sample_size = 25\n",
    "sample_variance = 0.006\n",
    "alpha = 0.01  # Significance level\n",
    "\n",
    "# Degrees of freedom\n",
    "df1 = sample_size - 1\n",
    "df2 = 1  # Degrees of freedom for the claimed population variance\n",
    "\n",
    "# Critical F-value for a two-tailed test\n",
    "critical_f = f.ppf(1 - alpha / 2, df1, df2)\n",
    "\n",
    "# F-test statistic\n",
    "f_statistic = sample_variance / claimed_variance\n",
    "\n",
    "# P-value for the F-test\n",
    "p_value = 2 * min(f.cdf(f_statistic, df1, df2), 1 - f.cdf(f_statistic, df1, df2))\n",
    "\n",
    "# Print results\n",
    "print(f\"Critical F-value: {critical_f}\")\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Compare with critical value\n",
    "if abs(f_statistic) > critical_f:\n",
    "    print(\"Reject the null hypothesis. The claim is not justified.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. The claim is justified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2537d10-ff90-4ffc-8dce-f4f6f7274fd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#Ans 06:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d89a59-a427-480b-95f5-70951c7e71f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the F-distribution: 1.1111111111111112\n",
      "Variance of the F-distribution: 1.0802469135802468\n"
     ]
    }
   ],
   "source": [
    "def f_distribution_mean_variance(df_num, df_den):\n",
    "    \"\"\"\n",
    "    Calculate the mean and variance of the F-distribution.\n",
    "\n",
    "    Parameters:\n",
    "    - df_num: Degrees of freedom for the numerator.\n",
    "    - df_den: Degrees of freedom for the denominator.\n",
    "\n",
    "    Returns:\n",
    "    - mean: Mean of the F-distribution.\n",
    "    - variance: Variance of the F-distribution.\n",
    "    \"\"\"\n",
    "    # Calculate mean\n",
    "    mean = df_den / (df_den - 2)\n",
    "\n",
    "    # Calculate variance\n",
    "    numerator = 2 * df_den**2 * (df_num + df_den - 2)\n",
    "    denominator = df_num * (df_den - 2)**2 * (df_den - 4)\n",
    "    variance = numerator / denominator\n",
    "\n",
    "    return mean, variance\n",
    "\n",
    "# Example usage:\n",
    "df_num = 3  # Replace with the actual degrees of freedom for the numerator\n",
    "df_den = 20  # Replace with the actual degrees of freedom for the denominator\n",
    "\n",
    "mean, variance = f_distribution_mean_variance(df_num, df_den)\n",
    "\n",
    "print(f\"Mean of the F-distribution: {mean}\")\n",
    "print(f\"Variance of the F-distribution: {variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40536427-1ae1-4e79-be6d-443f4b71c671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#Ans 07:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b27872dc-c4b8-4797-a500-7875cfd60995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To conduct an F-test for the equality of variances between two populations,\n",
    "# the null hypothesis (H0) is that the variances are equal, and\n",
    "# the alternative hypothesis (H1) is that the variances are not equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e477687b-2134-40e7-8f84-81c20086cadb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical F-value: 2.6457907352338195\n",
      "F-statistic: 1.25\n",
      "P-value: 0.6832194382585954\n",
      "Fail to reject the null hypothesis. No significant difference in variances.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "# Given data\n",
    "sample_variance1 = 25\n",
    "sample_size1 = 10\n",
    "df1 = sample_size1 - 1\n",
    "\n",
    "sample_variance2 = 20\n",
    "sample_size2 = 15\n",
    "df2 = sample_size2 - 1\n",
    "\n",
    "alpha = 0.10  # Significance level\n",
    "\n",
    "# Critical F-value for a two-tailed test\n",
    "critical_f = f.ppf(1 - alpha / 2, df1, df2)\n",
    "\n",
    "# F-test statistic\n",
    "f_statistic = sample_variance1 / sample_variance2\n",
    "\n",
    "# P-value for the F-test\n",
    "p_value = 2 * min(f.cdf(f_statistic, df1, df2), 1 - f.cdf(f_statistic, df1, df2))\n",
    "\n",
    "# Print results\n",
    "print(f\"Critical F-value: {critical_f}\")\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Compare with critical value\n",
    "if abs(f_statistic) > critical_f:\n",
    "    print(\"Reject the null hypothesis. Variances are significantly different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. No significant difference in variances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b6e08ed-67bc-4df2-be26-b82e842c6ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#Ans 08:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "793f549f-e20e-4f8c-8fe1-4493ad1b7a95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Variance (Restaurant A): 7.80952380952381\n",
      "Sample Variance (Restaurant B): 5.366666666666667\n",
      "F-statistic: 1.4551907719609583\n",
      "Critical F-value: 6.977701858535566\n",
      "P-value: 0.6974815747937484\n",
      "Fail to reject the null hypothesis. No significant difference in variances.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "# Given data\n",
    "waiting_times_a = np.array([24, 25, 28, 23, 22, 20, 27])\n",
    "waiting_times_b = np.array([31, 33, 35, 30, 32, 36])\n",
    "\n",
    "# Sample variances\n",
    "variance_a = np.var(waiting_times_a, ddof=1)\n",
    "variance_b = np.var(waiting_times_b, ddof=1)\n",
    "\n",
    "# Degrees of freedom\n",
    "df_a = len(waiting_times_a) - 1\n",
    "df_b = len(waiting_times_b) - 1\n",
    "\n",
    "# F-test statistic\n",
    "f_statistic = variance_a / variance_b\n",
    "\n",
    "# Critical F-value for a two-tailed test\n",
    "alpha = 0.05  # Significance level\n",
    "critical_f = f.ppf(1 - alpha / 2, df_a, df_b)\n",
    "\n",
    "# P-value for the F-test\n",
    "p_value = 2 * min(f.cdf(f_statistic, df_a, df_b), 1 - f.cdf(f_statistic, df_a, df_b))\n",
    "\n",
    "# Print results\n",
    "print(f\"Sample Variance (Restaurant A): {variance_a}\")\n",
    "print(f\"Sample Variance (Restaurant B): {variance_b}\")\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"Critical F-value: {critical_f}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Compare with critical value\n",
    "if abs(f_statistic) > critical_f:\n",
    "    print(\"Reject the null hypothesis. Variances are significantly different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. No significant difference in variances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "161559cb-21e2-4ce1-bd7c-f3834b059379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#Ans 09:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1939dd6-29e9-42b5-a8d8-2e5801185f31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Variance (Group A): 19.76666666666667\n",
      "Sample Variance (Group B): 10.166666666666666\n",
      "F-statistic: 1.9442622950819677\n",
      "Critical F-value: 14.939605459912224\n",
      "P-value: 0.4831043549070688\n",
      "Fail to reject the null hypothesis. No significant difference in variances.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "# Given data\n",
    "scores_group_a = np.array([80, 85, 90, 92, 87, 83])\n",
    "scores_group_b = np.array([75, 78, 82, 79, 81, 84])\n",
    "\n",
    "# Sample variances\n",
    "variance_group_a = np.var(scores_group_a, ddof=1)\n",
    "variance_group_b = np.var(scores_group_b, ddof=1)\n",
    "\n",
    "# Degrees of freedom\n",
    "df_group_a = len(scores_group_a) - 1\n",
    "df_group_b = len(scores_group_b) - 1\n",
    "\n",
    "# F-test statistic\n",
    "f_statistic = variance_group_a / variance_group_b\n",
    "\n",
    "# Critical F-value for a two-tailed test\n",
    "alpha = 0.01  # Significance level\n",
    "critical_f = f.ppf(1 - alpha / 2, df_group_a, df_group_b)\n",
    "\n",
    "# P-value for the F-test\n",
    "p_value = 2 * min(f.cdf(f_statistic, df_group_a, df_group_b), 1 - f.cdf(f_statistic, df_group_a, df_group_b))\n",
    "\n",
    "# Print results\n",
    "print(f\"Sample Variance (Group A): {variance_group_a}\")\n",
    "print(f\"Sample Variance (Group B): {variance_group_b}\")\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"Critical F-value: {critical_f}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Compare with critical value\n",
    "if abs(f_statistic) > critical_f:\n",
    "    print(\"Reject the null hypothesis. Variances are significantly different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. No significant difference in variances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caee0a3d-a82d-492b-b21f-aa67e9b4dfff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
