{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e269df16-d830-4e5f-b602-d5ae18e1b6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Ans 01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e97a497c-5ca1-40f1-baf4-c5ac7ff98dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analysis of Variance (ANOVA) is a statistical method used to compare means among multiple groups. However, for\n",
    "# ANOVA results to be valid, several assumptions must be met. Violations of these assumptions can lead to inaccurate\n",
    "# conclusions. The key assumptions of ANOVA include:\n",
    "\n",
    "# Normality: The dependent variable should be approximately normally distributed within each group. This assumption is more\n",
    "# critical when sample sizes are small. Violations may lead to inflated Type I error rates.\n",
    "# Example of Violation: If the data in one or more groups significantly deviate from normality, it may affect the ANOVA results.\n",
    "# For instance, if a group has a highly skewed or heavy-tailed distribution, it could impact the overall analysis.\n",
    "\n",
    "# Homogeneity of Variances (Homoscedasticity): The variances of the dependent variable should be roughly equal across all groups.\n",
    "# This assumption is important because ANOVA is sensitive to unequal variances, and violating this assumption may lead to\n",
    "# inaccurate p-values and confidence intervals.\n",
    "# Example of Violation: If the variances in one group are much larger or smaller than those in other groups, it can affect the\n",
    "# overall ANOVA results. This is often observed in situations where there are outliers or when the groups have different levels of\n",
    "# variability.\n",
    "\n",
    "# Independence of Observations: Observations within and between groups should be independent. Independence is crucial to ensure\n",
    "# that the variability observed in the dependent variable is due to differences between groups and not influenced by dependencies\n",
    "# among observations.\n",
    "# Example of Violation: If there is dependence among observations (e.g., repeated measures or nested designs), it can lead to\n",
    "# pseudoreplication and impact the validity of ANOVA results.\n",
    "\n",
    "# Random Sampling: Data should ideally be collected through random sampling. This assumption is necessary for making inferences\n",
    "# about a population based on the sample data.\n",
    "# Example of Violation: If the sampling process is not random, it may introduce bias into the sample, making it less representative\n",
    "# of the population. This can affect the generalizability of the ANOVA results.\n",
    "\n",
    "# Additivity: The effects of different factors should be additive, meaning that the total effect of two or more factors on the\n",
    "# dependent variable is the sum of their individual effects.\n",
    "# Example of Violation: If there are interactions between factors (i.e., the effects of factors are not purely additive), it can\n",
    "# complicate the interpretation of main effects and may require more sophisticated statistical techniques.\n",
    "\n",
    "# When these assumptions are violated, alternative methods or transformations may be considered, or non-parametric alternatives\n",
    "# like the Kruskal-Wallis test could be used. Additionally, diagnostic tests and graphical methods can help assess the validity of\n",
    "# assumptions before relying on ANOVA results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c753ca-631f-40ff-84f1-774a1096d403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#Ans 02:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd18b44-6417-47e3-9eaa-373a25ba9a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analysis of Variance (ANOVA) can be classified into three main types based on the experimental design and the\n",
    "# number of factors involved. These three types are:\n",
    "\n",
    "\n",
    "# One-Way ANOVA (One-Factor ANOVA):\n",
    "\n",
    "# Situation: Used when there is only one independent variable (factor) with more than two levels or groups.\n",
    "# Example: Suppose you want to compare the mean scores of three different teaching methods (A, B, C) to determine if there\n",
    "# is a significant difference in student performance.\n",
    "\n",
    "\n",
    "# Two-Way ANOVA:\n",
    "\n",
    "# Situation: Used when there are two independent variables (factors) that are crossed (meaning each level of one factor is\n",
    "# combined with each level of the other).\n",
    "# Example: You might use a two-way ANOVA to study the effects of both the type of diet (Factor 1: Low-fat, High-fat) and the\n",
    "# type of exercise (Factor 2: Cardio, Weight-lifting) on weight loss.\n",
    "\n",
    "# Repeated Measures ANOVA:\n",
    "\n",
    "# Situation: Used when measurements are taken on the same subjects or at multiple time points, resulting in repeated observations.\n",
    "# Example: Suppose you measure the blood pressure of the same group of individuals before and after three different treatments.\n",
    "# Repeated Measures ANOVA would be appropriate to assess whether there are significant differences among the treatments while\n",
    "# accounting for the repeated nature of the measurements within individuals.\n",
    "\n",
    "\n",
    "# Each type of ANOVA is suited to different experimental designs and research questions. The choice between them depends on the\n",
    "# structure of the data and the nature of the independent variables. It's important to correctly select the appropriate ANOVA\n",
    "# type to ensure the validity of the statistical analysis and the interpretation of results. Additionally, post-hoc tests or\n",
    "# pairwise comparisons may be applied after ANOVA to identify specific group differences\n",
    "# if the overall test indicates significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f34f4b-7e3b-4c23-8ab3-a3de908892aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#Ans 03:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c698f8-57fe-45a3-a227-22718efb2acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The partitioning of variance in Analysis of Variance (ANOVA) refers to the division of the total variance observed\n",
    "# in the dependent variable into different components that can be attributed to specific sources or factors. Understanding\n",
    "# this concept is crucial because it allows researchers to quantify the relative contributions of various factors to the\n",
    "# overall variability in the data. The total variance is decomposed into several components, which are:\n",
    "\n",
    "# Between-Group Variance (SSB): This component represents the variability in the dependent variable that can be attributed to\n",
    "# differences between the group means. It is a measure of the overall group effect.\n",
    "\n",
    "# Within-Group Variance (SSW): This component represents the variability within each group or condition. It reflects the random\n",
    "# variability or error in the data that cannot be explained by the group means.\n",
    "\n",
    "# Total Variance (SST): This is the overall variability in the dependent variable, and it is the sum of the between-group variance\n",
    "# and the within-group variance. Mathematically, SST = SSB + SSW.\n",
    "\n",
    "\n",
    "# The partitioning of variance is typically presented in the form of an ANOVA table, which summarizes the sources of variability,\n",
    "# degrees of freedom, sum of squares, mean squares, and F-ratios.\n",
    "\n",
    "\n",
    "# Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "# Assessing Group Differences: By examining the between-group variance, researchers can determine whether there are significant\n",
    "# differences among the group means. This is the primary goal of ANOVA.\n",
    "\n",
    "# Quantifying the Impact of Factors: The partitioning allows researchers to quantify the proportion of total variance that can\n",
    "# be explained by the independent variable(s). This helps in understanding the relative importance of different factors in\n",
    "# influencing the dependent variable.\n",
    "\n",
    "# Interpretation of F-ratio: The F-ratio, calculated as the ratio of between-group variance to within-group variance, provides\n",
    "# a measure of how much the group means differ relative to the random variability within groups.\n",
    "\n",
    "# Basis for Post-hoc Tests: If the overall ANOVA is significant, post-hoc tests or pairwise comparisons are often conducted to\n",
    "# identify which specific groups differ from each other. The partitioning of variance helps guide these additional analyses.\n",
    "\n",
    "# In summary, the partitioning of variance in ANOVA is essential for a comprehensive understanding of the sources of variability\n",
    "# in the data, the effects of independent variables, and the overall significance of the observed group differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80d1ca3f-64a8-468c-8637-6fd7c8972120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#Ans 04:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8033e19-46af-4dcc-8a73-c0f8c9b01208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) in\n",
    "# a one-way ANOVA using Python, you can use libraries such as NumPy or Scipy. Here's an example using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d58d2606-fdb7-476e-a277-7e7c2cded503",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 130.0\n",
      "Explained Sum of Squares (SSE): 10.0\n",
      "Residual Sum of Squares (SSR): 120.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data for each group\n",
    "group1 = np.array([4, 6, 8, 10, 12])\n",
    "group2 = np.array([3, 5, 7, 9, 11])\n",
    "group3 = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate overall mean\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate Total Sum of Squares (SST)\n",
    "sst = np.sum((data - overall_mean)**2)\n",
    "\n",
    "# Calculate group means\n",
    "group1_mean = np.mean(group1)\n",
    "group2_mean = np.mean(group2)\n",
    "group3_mean = np.mean(group3)\n",
    "\n",
    "# Calculate Explained Sum of Squares (SSE)\n",
    "sse = len(group1) * (group1_mean - overall_mean)**2 + \\\n",
    "      len(group2) * (group2_mean - overall_mean)**2 + \\\n",
    "      len(group3) * (group3_mean - overall_mean)**2\n",
    "\n",
    "# Calculate Residual Sum of Squares (SSR)\n",
    "ssr = np.sum((group1 - group1_mean)**2) + \\\n",
    "      np.sum((group2 - group2_mean)**2) + \\\n",
    "      np.sum((group3 - group3_mean)**2)\n",
    "\n",
    "# Print the results\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5b8104b-0111-4e72-b6bf-4f3d3ef4b1fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In this example, group1, group2, and group3 represent the data for three groups. The SST is calculated by summing\n",
    "# the squared differences between each data point and the overall mean. The SSE is calculated by summing the squared\n",
    "# differences between each group mean and the overall mean, weighted by the number of observations in each group.\n",
    "# The SSR is then obtained by subtracting SSE from SST.\n",
    "\n",
    "# Note: This is a simplified example, and in practice, you might use specialized libraries like Scipy's stats.f_oneway\n",
    "# function to perform a one-way ANOVA, which automatically calculates these values along with the F-statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a62469a1-4aec-4f57-a5b3-19cdf4dd2a5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#Ans 05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d42f91b2-7fee-40ea-b314-635468e45560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor 1: F = 3.7909706477569953 , p = 0.08621209605597369\n",
      "Main Effect of Factor 2: F = 0.2984276677012813 , p = 0.6045729043804502\n",
      "Interaction Effect: F = 5.200679840963948 , p = 0.048956931869770126\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'Factor1': np.repeat(['A', 'B', 'C'], 4),\n",
    "    'Factor2': np.tile(['X', 'Y'], 6),\n",
    "    'Value': np.random.randn(12)\n",
    "})\n",
    "\n",
    "# Calculate means\n",
    "overall_mean = data['Value'].mean()\n",
    "mean_factor1 = data.groupby('Factor1')['Value'].mean()\n",
    "mean_factor2 = data.groupby('Factor2')['Value'].mean()\n",
    "mean_interaction = data.groupby(['Factor1', 'Factor2'])['Value'].mean()\n",
    "\n",
    "# Degrees of freedom\n",
    "df_total = len(data) - 1\n",
    "df_factor1 = len(mean_factor1) - 1\n",
    "df_factor2 = len(mean_factor2) - 1\n",
    "df_interaction = (len(mean_factor1) - 1) * (len(mean_factor2) - 1)\n",
    "df_residual = df_total - (df_factor1 + df_factor2 + df_interaction)\n",
    "\n",
    "# Sum of squares\n",
    "sst = np.sum((data['Value'] - overall_mean)**2)\n",
    "ss_factor1 = np.sum((mean_factor1 - overall_mean)**2 * data.groupby('Factor1').size())\n",
    "ss_factor2 = np.sum((mean_factor2 - overall_mean)**2 * data.groupby('Factor2').size())\n",
    "ss_interaction = np.sum((mean_interaction - overall_mean)**2 * data.groupby(['Factor1', 'Factor2']).size())\n",
    "ss_residual = sst - (ss_factor1 + ss_factor2 + ss_interaction)\n",
    "\n",
    "# Mean squares\n",
    "ms_factor1 = ss_factor1 / df_factor1\n",
    "ms_factor2 = ss_factor2 / df_factor2\n",
    "ms_interaction = ss_interaction / df_interaction\n",
    "ms_residual = ss_residual / df_residual\n",
    "\n",
    "# F-statistics\n",
    "f_factor1 = ms_factor1 / ms_residual\n",
    "f_factor2 = ms_factor2 / ms_residual\n",
    "f_interaction = ms_interaction / ms_residual\n",
    "\n",
    "# p-values\n",
    "p_factor1 = 1 - f.cdf(f_factor1, df_factor1, df_residual)\n",
    "p_factor2 = 1 - f.cdf(f_factor2, df_factor2, df_residual)\n",
    "p_interaction = 1 - f.cdf(f_interaction, df_interaction, df_residual)\n",
    "\n",
    "# Print results\n",
    "print(\"Main Effect of Factor 1: F =\", f_factor1, \", p =\", p_factor1)\n",
    "print(\"Main Effect of Factor 2: F =\", f_factor2, \", p =\", p_factor2)\n",
    "print(\"Interaction Effect: F =\", f_interaction, \", p =\", p_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ed62711-ba24-49c8-8dd7-545627a2d280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#Ans 06:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b774a490-52b5-4200-90f7-fc31bb902625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In a one-way ANOVA, the F-statistic is used to test the null hypothesis that the means of the groups are equal.\n",
    "# A small p-value suggests that you can reject the null hypothesis. In your case, with an F-statistic of 5.23 and\n",
    "# a p-value of 0.02, the p-value is less than the commonly used significance level of 0.05.\n",
    "\n",
    "# Here's how you can interpret these results:\n",
    "\n",
    "# Null Hypothesis (H0): The means of the groups are equal.\n",
    "# Alternative Hypothesis (H1): At least one group mean is different from the others.\n",
    "\n",
    "# Since the p-value (0.02) is less than the significance level (commonly chosen as 0.05), you would reject the null hypothesis.\n",
    "# This suggests that there is enough evidence to conclude that there are significant differences between the groups.\n",
    "\n",
    "# In practical terms, you can say that there are statistically significant variations in the means of the groups you are\n",
    "# comparing. However, the ANOVA itself does not tell you which specific groups are different from each other. If you reject the\n",
    "# null hypothesis, it is common practice to conduct post-hoc tests or pairwise comparisons to identify which groups differ.\n",
    "\n",
    "# In summary, based on the results of your one-way ANOVA:\n",
    "\n",
    "# Conclusion: There are statistically significant differences between the groups.\n",
    "# Next Steps: Conduct post-hoc tests to determine which specific groups are different from each other.\n",
    "\n",
    "# Keep in mind that statistical significance doesn't necessarily imply practical significance, and it's crucial to consider the\n",
    "# context of the study and the magnitude of the differences in addition to the statistical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e180215-3f1d-405c-91a4-0165707ac0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#Ans 07:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2295c54-f089-4554-8049-5bd3cb792e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dealing with missing data in repeated measures ANOVA is important for obtaining valid and reliable results. There\n",
    "# are various methods to handle missing data, each with its own assumptions and potential consequences. Here are some\n",
    "# common approaches:\n",
    "\n",
    "    \n",
    "# Complete Case Analysis (Listwise Deletion):\n",
    "# Method: Exclude participants with missing data on any variable involved in the analysis.\n",
    "# Consequences: This method can lead to a loss of statistical power and potentially biased results, especially if the missing\n",
    "# data is not completely at random (MCAR). It may also introduce selection bias if the missingness is related to the variables\n",
    "# under study.\n",
    "\n",
    "# Pairwise Deletion:\n",
    "# Method: Analyze all available data for each pair of variables, excluding only cases with missing data on the specific\n",
    "# variables being analyzed.\n",
    "# Consequences: While it utilizes more data than listwise deletion, it can lead to biased estimates if the missing data is\n",
    "# related to the variables being analyzed. The results may be inconsistent across different pairwise comparisons.\n",
    "\n",
    "# Imputation Techniques:\n",
    "# Method: Impute missing values based on observed values and/or other variables.\n",
    "# Consequences: Imputation methods, such as mean imputation, regression imputation, or multiple imputation, can introduce bias if\n",
    "# the assumptions underlying the imputation model are violated. However, they can provide more reliable estimates than complete\n",
    "# case analysis when the missing data is related to other observed variables.\n",
    "\n",
    "# Last Observation Carried Forward (LOCF):\n",
    "# Method: Impute missing values using the last observed value for each participant.\n",
    "# Consequences: LOCF assumes that the missing values remain constant over time, which may not be the case. This method may lead\n",
    "# to biased results, especially if there is a trend or pattern in the missing data.\n",
    "\n",
    "# Interpolation or Extrapolation:\n",
    "# Method: Estimate missing values based on patterns or trends observed in the available data.\n",
    "# Consequences: This method assumes that the missing values follow a specific pattern, which may not be accurate. Extrapolation,\n",
    "# in particular, can be risky if it extends beyond the observed range of data.\n",
    "\n",
    "# Maximum Likelihood Estimation (MLE):\n",
    "# Method: Incorporates the likelihood of the observed data given the missing data into the analysis.\n",
    "# Consequences: MLE provides unbiased estimates under the assumption that the missing data is missing at random (MAR). However,\n",
    "# the MAR assumption is critical for the validity of this method.\n",
    "\n",
    "\n",
    "# When choosing a method, researchers should carefully consider the nature of the missing data and the assumptions of the imputation\n",
    "# technique. Multiple imputation is often recommended when dealing with missing data as it accounts for uncertainty related to\n",
    "# imputation. However, the choice of method depends on the specific characteristics of the dataset and the research context.\n",
    "# It's also essential to report any methods used to handle missing data and conduct sensitivity analyses to assess the robustness\n",
    "# of the results to different missing data handling strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a390825-8246-42ef-a6e9-0c5126a411e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#Ans 08:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e4cba93-99f1-4a35-8737-817b868e289f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Post-hoc tests are used after ANOVA to make detailed comparisons between group means when the overall ANOVA\n",
    "# result indicates that there are significant differences among groups. Some common post-hoc tests include:\n",
    "\n",
    "# Tukey's Honestly Significant Difference (HSD):\n",
    "# When to Use: Use Tukey's HSD when you have conducted a one-way ANOVA and want to compare all possible pairs of group means.\n",
    "# It controls the familywise error rate.\n",
    "# Example: You conducted a one-way ANOVA to compare the performance of three different teaching methods, and the ANOVA result\n",
    "# is significant. Tukey's HSD can be used to identify which specific teaching methods differ significantly in terms of student\n",
    "# performance.\n",
    "\n",
    "# Bonferroni Correction:\n",
    "# When to Use: Bonferroni is a conservative correction method. Use it when making multiple pairwise comparisons in a one-way\n",
    "# ANOVA or in situations where you want to control the overall type I error rate.\n",
    "# Example: You have conducted a one-way ANOVA to compare the mean scores of four different groups. The overall ANOVA result is\n",
    "# significant, and you want to perform pairwise comparisons while controlling the familywise error rate. Bonferroni correction\n",
    "# can be applied in this case.\n",
    "\n",
    "# Sidak Correction:\n",
    "# When to Use: Similar to Bonferroni, Sidak correction is used for multiple comparisons after ANOVA. It is less conservative than\n",
    "# Bonferroni but still controls the familywise error rate.\n",
    "# Example: After conducting a two-way ANOVA to analyze the effects of two factors on a dependent variable, you want to perform\n",
    "# multiple pairwise comparisons. Sidak correction can be applied to control the overall type I error rate.\n",
    "\n",
    "# Dunnett's Test:\n",
    "# When to Use: Use Dunnett's test when you have a control group, and you want to compare other groups against the control group.\n",
    "# Example: In a medical study, you have a control group receiving a placebo and several treatment groups. After conducting an ANOVA,\n",
    "# you can use Dunnett's test to compare each treatment group with the control group.\n",
    "\n",
    "# Holm's Method:\n",
    "# When to Use: Holm's method is a step-down procedure that controls the familywise error rate. It is less conservative than\n",
    "# Bonferroni but still provides strong control.\n",
    "# Example: In a factorial ANOVA with multiple factors, you may want to perform post-hoc tests to compare specific groups while\n",
    "# controlling the overall type I error rate. Holm's method can be applied for this purpose.\n",
    "\n",
    "# Games-Howell Test:\n",
    "# When to Use: Games-Howell is used when the assumption of equal variances is violated. It is a more robust alternative to Tukey's\n",
    "# HSD in such cases.\n",
    "# Example: In a one-way ANOVA where the assumption of homogeneity of variances is not met, you can use Games-Howell to perform\n",
    "# post-hoc tests and compare group means.\n",
    "\n",
    "\n",
    "# Example Situation:\n",
    "# Suppose you conducted a one-way ANOVA to compare the effectiveness of four different training programs on employee productivity.\n",
    "# The ANOVA indicates that there are significant differences among the groups. In this scenario, you might employ Tukey's HSD,\n",
    "# Bonferroni, or Sidak correction for post-hoc tests to identify which specific training programs result in significantly different\n",
    "# levels of productivity. This allows you to make detailed pairwise comparisons and draw more specific conclusions about the\n",
    "# effectiveness of the training programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64c0a913-dabc-45bb-8404-3c5339843d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#Ans 09:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0910b777-d87e-482a-b290-12f05a1db7c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 67.61854911979148\n",
      "p-value: 1.5055246613126342e-21\n",
      "The one-way ANOVA result is statistically significant.\n",
      "There is evidence to suggest that there are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)  # for reproducibility\n",
    "diet_A = np.random.normal(5, 1, 50)  # mean weight loss of 5 with standard deviation 1\n",
    "diet_B = np.random.normal(6, 1, 50)  # mean weight loss of 6 with standard deviation 1\n",
    "diet_C = np.random.normal(7, 1, 50)  # mean weight loss of 7 with standard deviation 1\n",
    "\n",
    "# Combine data into a single array\n",
    "data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "# Create group labels\n",
    "labels = ['A'] * 50 + ['B'] * 50 + ['C'] * 50\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret results\n",
    "if p_value < 0.05:\n",
    "    print(\"The one-way ANOVA result is statistically significant.\")\n",
    "    print(\"There is evidence to suggest that there are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"The one-way ANOVA result is not statistically significant.\")\n",
    "    print(\"There is no strong evidence to suggest differences between the mean weight loss of the three diets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ab96f04-547f-44d0-a3de-dcec5350d13e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#Ans 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8cb676f-5540-48e7-b3c1-7575cb2c4387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            df      sum_sq   mean_sq         F    PR(>F)\n",
      "C(Program)                 2.0    2.514772  1.257386  0.344485  0.709581\n",
      "C(Experience)              1.0    0.479063  0.479063  0.131248  0.718051\n",
      "C(Program):C(Experience)   2.0    1.592393  0.796197  0.218133  0.804472\n",
      "Residual                  84.0  306.603758  3.650045       NaN       NaN\n",
      "There is no significant main effect of software programs.\n",
      "There is no significant main effect of experience level.\n",
      "There is no significant interaction effect between software programs and experience level.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "# Create a DataFrame with columns 'Time', 'Program', and 'Experience'\n",
    "data = pd.DataFrame({\n",
    "    'Time': np.random.normal(loc=10, scale=2, size=90),\n",
    "    'Program': np.repeat(['A', 'B', 'C'], 30),\n",
    "    'Experience': np.tile(['Novice', 'Experienced'], 45)\n",
    "})\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "formula = 'Time ~ C(Program) + C(Experience) + C(Program):C(Experience)'\n",
    "model = ols(formula, data).fit()\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "# Print results\n",
    "print(anova_results)\n",
    "\n",
    "# Interpret results\n",
    "p_program = anova_results['PR(>F)']['C(Program)']\n",
    "p_experience = anova_results['PR(>F)']['C(Experience)']\n",
    "p_interaction = anova_results['PR(>F)']['C(Program):C(Experience)']\n",
    "\n",
    "if p_program < 0.05:\n",
    "    print(\"There is a significant main effect of software programs on task completion time.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of software programs.\")\n",
    "\n",
    "if p_experience < 0.05:\n",
    "    print(\"There is a significant main effect of experience level on task completion time.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of experience level.\")\n",
    "\n",
    "if p_interaction < 0.05:\n",
    "    print(\"There is a significant interaction effect between software programs and experience level.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction effect between software programs and experience level.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc4659cf-ca8f-4b8f-98f9-56a25e075ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#Ans 11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc19335e-eaa7-4e73-8d61-5f9b66b01d54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "T-statistic: -4.108723928204809\n",
      "P-value: 8.261945608702611e-05\n",
      "There is a significant difference in test scores between the control and experimental groups.\n",
      "Proceed with post-hoc tests.\n",
      "\n",
      "Post-hoc (Tukey's HSD) results:\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1    group2    meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "Control Experimental   7.4325 0.0001 3.8427 11.0224   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)  # for reproducibility\n",
    "control_group = np.random.normal(loc=70, scale=10, size=50)\n",
    "experimental_group = np.random.normal(loc=75, scale=10, size=50)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print results\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret results\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in test scores between the control and experimental groups.\")\n",
    "    print(\"Proceed with post-hoc tests.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the control and experimental groups.\")\n",
    "\n",
    "# Post-hoc test (Tukey's HSD) if the results are significant\n",
    "if p_value < 0.05:\n",
    "    # Combine data for post-hoc test\n",
    "    all_data = np.concatenate([control_group, experimental_group])\n",
    "    group_labels = np.concatenate([['Control'] * 50, ['Experimental'] * 50])\n",
    "\n",
    "    # Perform Tukey's HSD post-hoc test\n",
    "    tukey_results = pairwise_tukeyhsd(all_data, group_labels)\n",
    "\n",
    "    # Print post-hoc results\n",
    "    print(\"\\nPost-hoc (Tukey's HSD) results:\")\n",
    "    print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bc1500c-dff7-4c72-abcc-cb16f5d4f501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In this example, I generated random test scores for the control and experimental groups using normal\n",
    "# distributions. Replace this data with your actual test score data.\n",
    "\n",
    "# The two-sample t-test is performed using the ttest_ind function from scipy.stats. If the results are significant\n",
    "# (p-value < 0.05), the code proceeds with a post-hoc test, in this case, Tukey's HSD, using the pairwise_tukeyhsd\n",
    "# function from statsmodels.\n",
    "\n",
    "# Remember to interpret the results cautiously, considering both statistical significance and practical significance.\n",
    "# The post-hoc test helps identify which specific groups differ significantly if there is a significant overall\n",
    "# difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2182b885-b1eb-413c-980d-11b3dcad150e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#Ans 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a2ee74b-823e-401b-a104-47c8b1989b05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way ANOVA results:\n",
      "F-statistic: 9.942655439164778\n",
      "P-value: 0.00012916754728826364\n",
      "There is a significant difference in sales between the three stores.\n",
      "Proceed with post-hoc tests.\n",
      "\n",
      "Post-hoc (Tukey's HSD) results:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "=======================================================\n",
      " group1  group2 meandiff p-adj   lower    upper  reject\n",
      "-------------------------------------------------------\n",
      "Store A Store B  21.3397 0.0001   9.7429 32.9365   True\n",
      "Store A Store C  14.0206 0.0136   2.4238 25.6175   True\n",
      "Store B Store C  -7.3191 0.2936 -18.9159  4.2778  False\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)  # for reproducibility\n",
    "sales_store_A = np.random.normal(loc=100, scale=20, size=30)\n",
    "sales_store_B = np.random.normal(loc=120, scale=20, size=30)\n",
    "sales_store_C = np.random.normal(loc=110, scale=20, size=30)\n",
    "\n",
    "# Combine data for one-way ANOVA\n",
    "all_sales_data = np.concatenate([sales_store_A, sales_store_B, sales_store_C])\n",
    "group_labels = np.concatenate([['Store A'] * 30, ['Store B'] * 30, ['Store C'] * 30])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(sales_store_A, sales_store_B, sales_store_C)\n",
    "\n",
    "# Print results\n",
    "print(\"One-way ANOVA results:\")\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret results\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in sales between the three stores.\")\n",
    "    print(\"Proceed with post-hoc tests.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in sales between the three stores.\")\n",
    "\n",
    "# Post-hoc test (Tukey's HSD) if the results are significant\n",
    "if p_value < 0.05:\n",
    "    # Perform Tukey's HSD post-hoc test\n",
    "    tukey_results = pairwise_tukeyhsd(all_sales_data, group_labels)\n",
    "\n",
    "    # Print post-hoc results\n",
    "    print(\"\\nPost-hoc (Tukey's HSD) results:\")\n",
    "    print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "033e9fd2-05cd-4d9f-80fa-d799152e0ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
